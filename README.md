# scrapy-boilerplate
### // read about processes here: https://docs.scrapy.org/en/latest/topics/practices.html#running-multiple-spiders-in-the-same-process
### // this allows you to run multiple spiders in the same process
### // the following sections are really useful: Running multiple spiders in the same process, Distributed crawls, Avoiding getting banned
